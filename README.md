# ğŸš€ AstroML Ops â€” NEO Hazard Classification (v1.0.0)

A complete **MLOps pipeline** to download NASA NEO (Near-Earth Objects) data, preprocess it, train a classifier for potentially hazardous asteroids, serve predictions via a FastAPI API, and monitor model drift with **Evidently** and experiment tracking with **MLflow**.

---

## ğŸ”­ Overview
- **Ingestion** â†’ Fetches NEO data from NASA's public API.
- **Preprocessing** â†’ Extracts relevant features, cleans data, and stores CSVs.
- **Training** â†’ RandomForest model (v1.0) with experiment logging in MLflow.
- **Serving** â†’ FastAPI REST API with `/predict`, `/health`, `/version` endpoints.
- **Monitoring** â†’ Drift detection with Evidently (HTML reports).
- **Pipeline** â†’ Single script to orchestrate the entire flow.

---

## ğŸ§± Project Structure

â”œâ”€â”€ notebooks/ # Jupyter notebook for EDA and experiments
â”œâ”€â”€ pipelines/ # Full pipeline orchestration  
â”œâ”€â”€ src/  
â”‚ â”œâ”€â”€ ingest/ # Data download from NASA  
â”‚ â”œâ”€â”€ preprocessing/ # Data cleaning and processing  
â”‚ â”œâ”€â”€ train/ # Model training + MLflow tracking  
â”‚ â”œâ”€â”€ serve/ # FastAPI app, prediction, schema  
â”‚ â””â”€â”€ evaluate/ # Drift reports with Evidently  
â”œâ”€â”€ data/processed/ # Processed CSVs  
â”œâ”€â”€ monitoring/  
â”‚ â”œâ”€â”€ reports/ # Drift reports, confusion matrix  
â”œâ”€â”€ tests/ # Smoke tests for API and best model test
â”œâ”€â”€ requirements.txt  
â”œâ”€â”€ docker-compose.yml  
â”œâ”€â”€ Dockerfile  
â”œâ”€â”€ .env.example  
â””â”€â”€ README.md

---

## âš™ï¸ Requirements
- Python **3.11+**
- (Optional) Docker + Docker Compose
- NASA API key â†’ [Get here](https://api.nasa.gov/)

---

## ğŸ”‘ Environment Variables
Create a `.env` file based on `.env.example`:  
`NASA_API_KEY=YOUR_KEY_HERE`

---

## ğŸš€ Running Locally (without Docker)

### Install dependencies
```bash
pip install -r requirements.txt
```

### Run full pipeline (ingest â†’ preprocess â†’ train â†’ drift reports)

**Windows (PowerShell):**
```bash
$env:PYTHONPATH="."; python pipelines/full_pipeline.py
```

**Linux/macOS:**
```bash
PYTHONPATH=. python pipelines/full_pipeline.py
```

### Start API
```bash
uvicorn src.serve.main:app --reload
```
Docs: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ğŸ³ Running with Docker
```bash
docker compose up --build
```
- API â†’ [http://localhost:8000/docs](http://localhost:8000/docs)
- MLflow â†’ [http://localhost:5000](http://localhost:5000)
- Drift reports â†’ `monitoring/reports/*.html`

---

## ğŸ” Monitoring & Tracking
- **Evidently** â†’ HTML reports for:
  - Training vs Current Data (drift_report.html)
  - Training vs API Inferences (api_drift_report.html)

- **MLflow** â†’ parameters, metrics, confusion matrix, classification report.

---

## ğŸ§ª API Endpoints
- **GET /health** â†’ Health check
- **GET /version** â†’ Model version
- **POST /predict** â†’ Example request:

```json
{
  "diameter_min_m": 120.0,
  "diameter_max_m": 250.0,
  "miss_distance_km": 80000,
  "velocity_kph": 90000
}
```

Response:
```json
{ "is_hazardous": true }
```

---

## âš  Known Issues
- **Inflated F1-score** â†’ Current version uses oversampling on the entire dataset, which may lead to unrealistically high F1.
- **Unrealistic inputs** â†’ Very atypical or extreme values may result in unexpected predictions.

---

## ğŸ—º Future Versions
- Oversample only on training set
- Cross-validation and hyperparameter tuning